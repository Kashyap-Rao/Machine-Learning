{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c538a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path().resolve()\n",
    "DATA = ROOT / 'data'  # This contains the path to the data/ folder of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c736961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Question 1.1 Load the data into the following numpy arrays. For the output, only use the first torque variable.\n",
    "# Randomly split the data from the file sarcos_inv.mat into a training set (80%) and a validation set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3664595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "data = r'C:\\Users\\kashy\\FML old\\FML-WS23-BPA1_v1\\notebooks\\data'\n",
    "\n",
    "# Use scipy.io to import the data\n",
    "\n",
    "# First, load the data sets as numpy arrays\n",
    "# Then, split it appropriately in the following variables\n",
    "# 1.1 a\n",
    "training_data_total = scipy.io.loadmat(os.path.join(data,\"sarcos_inv\"))['sarcos_inv']\n",
    "test_data = scipy.io.loadmat(os.path.join(data,\"sarcos_inv_test\"))['sarcos_inv_test']\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(training_data_total, axis=0)\n",
    "\n",
    "#1.1 b\n",
    "training_data=training_data_total[:int(training_data_total.shape[0]*0.8),:]\n",
    "validation_data=training_data_total[int(training_data_total.shape[0]*0.8):,:]\n",
    "\n",
    "# Input and output training data\n",
    "xs_train= training_data[:,:21]\n",
    "ys_train = training_data[:,21].reshape(-1,1)\n",
    "\n",
    "# Input and output validation data\n",
    "xs_valid = validation_data[:,:21]\n",
    "ys_valid = validation_data[:,21].reshape(-1,1)\n",
    "\n",
    "# Input and output test data\n",
    "xs_test = test_data[:,:21]\n",
    "ys_test = test_data[:,21].reshape(-1,1)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4b41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xs_train.shape == (35587, 21), \"xs_train should contain 35587 21-dimensional data points\"\n",
    "assert ys_train.shape == (35587, 1), \"ys_train should contain 35587 1-dimensional data points\"\n",
    "assert xs_valid.shape == (8897, 21), \"xs_valid should contain 8897 21-dimensional data points\"\n",
    "assert ys_valid.shape == (8897, 1), \"ys_valid should contain 8897 1-dimensional data points\"\n",
    "assert xs_test.shape == (4449, 21), \"xs_test should contain 4449 21-dimensional data points\"\n",
    "assert ys_test.shape == (4449, 1), \"ys_test should contain 4449 1-dimensional data points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5242bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2 Implement my_variance and my_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e80c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_variance(xs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Computes the sample variance of a given vector of scalars\n",
    "    \n",
    "    Args:\n",
    "        xs: 1D numpy array containing scalars\n",
    "    \n",
    "    Returns:\n",
    "        The empirical variance of the provided vector as a float\n",
    "    \"\"\"\n",
    "    return np.var(xs)\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df1aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks are to make sure that your function gives the correct sample variance in simple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fce0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(my_variance(np.array([1, 1, 1])), 0), \"Variance of this vector should be 0\"\n",
    "assert np.isclose(my_variance(np.array([1, 2, 3, 4, 5])), 2), \"Variance of this vector should be 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d4b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, implement the MSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbfb0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mse(z1: np.ndarray, z2: np.ndarray):\n",
    "    \"\"\" Computes the Mean Squared Error (MSE)\n",
    "    \n",
    "    Args:\n",
    "        z1: A 1D numpy array (usually the predictions).\n",
    "        z2: Another 1D numpy array.\n",
    "    \n",
    "    Returns\n",
    "        The MSE of the given data.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return np.square(np.subtract(z1,z2)).mean()\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d73d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks to make sure that your function gives the correct MSE in simple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a672c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(my_mse(np.array([3.0]), np.array([4.0])), 1), \"The MSE between 3 and 4 should be 1\"\n",
    "assert np.isclose(my_mse(np.array([1, 2, 3, 4]), np.array([1, 2, 3, 4])), 0), \"MSE should be 0 for identical z vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc90e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.3 Standardize the dataset you loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ebb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mean_only(y,y_t):\n",
    "    y=y-np.mean(y_t,axis=0)\n",
    "    return y\n",
    "def standardize(y,y_t):\n",
    "    y_s=np.empty(y.shape)\n",
    "    means=np.empty(y.shape[1])\n",
    "    dev=np.empty(y.shape[1])\n",
    "    for column in range (y.shape[1]):\n",
    "        this_column=y_t[:,column]\n",
    "        mean=np.mean(this_column, axis=0)\n",
    "        means[column]=mean\n",
    "        var=np.std(this_column, axis=0)\n",
    "        dev[column]=var\n",
    "        y_s[:,column]=(y[:,column]-mean)/var\n",
    "    return y_s,means,dev\n",
    "    \n",
    "xs_train_std = standardize(xs_train, xs_train)[0]\n",
    "ys_train_std = standardize_mean_only(ys_train,ys_train)\n",
    "xs_valid_std = standardize(xs_valid,xs_train)[0]\n",
    "ys_valid_std = standardize_mean_only(ys_valid,ys_train)\n",
    "xs_test_std = standardize(xs_test,xs_train)[0]\n",
    "ys_test_std = standardize_mean_only(ys_test,ys_train)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a929b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks to make sure that your standardization does not change the data shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11fbe51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xs_train_std.shape == xs_train.shape, \"Normalizing is not supposed to change the shape of your data\"\n",
    "assert ys_train_std.shape == ys_train.shape, \"Normalizing is not supposed to change the shape of your data\"\n",
    "assert xs_valid_std.shape == xs_valid.shape, \"Normalizing is not supposed to change the shape of your data\"\n",
    "assert ys_valid_std.shape == ys_valid.shape, \"Normalizing is not supposed to change the shape of your data\"\n",
    "assert xs_test_std.shape == xs_test.shape, \"Normalizing is not supposed to change the shape of your data\"\n",
    "assert ys_test_std.shape == ys_test.shape, \"Normalizing is not supposed to change the shape of your data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87d774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks to make sure that the training data has roughly mean 0 and variance 1 after standardizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da771ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(np.mean(xs_train_std), 0, atol=0.005), \"Training inputs mean should be 0\"\n",
    "assert np.isclose(np.mean(ys_train_std), 0, atol=0.005), \"Training outputs mean should be 0\"\n",
    "\n",
    "assert np.allclose(np.var(xs_train_std, axis=0), 1, atol=0.005), \"Training inputs variance should be 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1580c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "# Simple linear regression\n",
    "\n",
    "# Question 1.4 Implement a function that performs linear regression given input data and target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8902040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_linear_regression(phi: np.ndarray, ys: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Computes the weights of a linear regression that fits the given data.\n",
    "    \n",
    "    Notes:\n",
    "        You may use np.linalg.solve to solve a system of linear equations.\n",
    "    \n",
    "    Args:\n",
    "        phi: Input feature matrix of shape (N, D) containing N samples of dimension D.\n",
    "        ys: Target outputs of shape (N, 1) containing N 1-dimensional samples.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array containing the regressed weights of shape (D, 1), containing one weight for each input dimension.\n",
    "    \"\"\"\n",
    "    A=np.dot(phi.T, phi)\n",
    "    b=np.dot(phi.T, ys)\n",
    "    #w=np.linalg.solve(A,b)\n",
    "    w=np.dot(np.linalg.inv(A),b)\n",
    "    return w\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6545701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks to make sure your weights have the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c94d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "_my_weights = my_linear_regression(xs_train_std, ys_train_std)\n",
    "assert _my_weights.shape == (21, 1), \"Weights should have shape (D, 1).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b7fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    " # If everything is correct so far,MSE should be roughly 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ca74f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your MSE should be roughly 31 and it is 30.91609504174229.\n"
     ]
    }
   ],
   "source": [
    "_my_y_valid_pred = xs_valid_std @ _my_weights\n",
    "_my_mse = my_mse(ys_valid_std, _my_y_valid_pred)\n",
    "print(f\"Your MSE should be roughly 31 and it is {_my_mse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26d856dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Linear regression with polynomial features\n",
    "\n",
    " # Question 1.5 Implement a function that computes non-repeating features of degree up to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48811657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_quadratic_features(xs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Generates polynomial features up to degree 2 from given data.\n",
    "    \n",
    "    The quadratic features should include monomials (i.e., x_i, x_i**2 etc)\n",
    "    and interaction terms (x_1*x_2 etc), but no repetitions (i.e. NOT both x_1*x_2 and x_2*x_1).\n",
    "    You should include a bias term.\n",
    "    The order of the samples should not be changed through the transformation.\n",
    "    \n",
    "    Args:\n",
    "        xs: A 2D numpy array of shape (N, D) containing N samples of dimension D.\n",
    "    \n",
    "    Returns:\n",
    "        An (N, M) numpy array containing the transformed input.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    phi=[]\n",
    "    for x in xs:\n",
    "        phi_i=np.array([1,x[0]**1,x[1]**1,x[0]*x[1],x[0]**2,x[1]**2]).T\n",
    "        phi.append(phi_i)\n",
    "    return np.asarray(phi)\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98e62729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks are to make sure that the function produces the correct number of features in simple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf397ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert my_quadratic_features(np.array([[0, 1]])).shape == (1, 6), \"For 2D data, your function should produce 6D quadratic features.\"\n",
    "assert my_quadratic_features(np.array([[0, 1], [2, 3]])).shape == (2, 6), \"Your function should produce 6D quadratic features for every data point.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f70aa9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks are to make sure that the function produces the correct features in simple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "659a231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_01_quadratic_features = my_quadratic_features(np.array([[0, 1]]))\n",
    "assert {0, 1} == set(*_01_quadratic_features), \"Quadratic features of [0, 1] should include only 0s and 1s.\"\n",
    "_count_0 = np.count_nonzero(_01_quadratic_features == 0)\n",
    "_count_1 = np.count_nonzero(_01_quadratic_features == 1)\n",
    "assert _count_0 == 3, \"Quadratic features of [0, 1] should include 3 zeros (x_0, x_0**2, x_0*x_1)\"\n",
    "assert _count_1 == 3, \"Quadratic features of [0, 1] should include 3 ones (bias, x_1, x_1 ** 2)\"\n",
    "\n",
    "assert {1, 4, 5, 16, 20, 25} == set(*my_quadratic_features(np.array([[4, 5]]))), \"Quadratic features of [4, 5] should be any permutation of [1, 4, 5, 16, 20, 25].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4fe852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.7 Generate polynomial features of up to degree 3 from your standardized train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad5b0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly=PolynomialFeatures(degree=3)\n",
    "xs_train_polynomial = poly.fit_transform(xs_train_std)\n",
    "xs_valid_polynomial = poly.fit_transform(xs_valid_std)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70d76a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following checks are to make sure that the resulting polynomial features have the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fb14f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xs_train_polynomial.shape == (35587, 2024)\n",
    "assert xs_valid_polynomial.shape == (8897, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a242b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run linear regression with polynomial features to obtain the optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dc39a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "_my_weights = my_linear_regression(xs_train_polynomial, ys_train_std)\n",
    "assert _my_weights.shape == (2024, 1), \"Weights should have shape (D, 1).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e61677b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model on the validation data. If you implemented everything correctly so far, you should now get an MSE of roughly 6.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d91feac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your MSE should be roughly 6.8 and it is 6.754390190633654.\n"
     ]
    }
   ],
   "source": [
    "_my_y_valid_pred = xs_valid_polynomial @ _my_weights\n",
    "_my_mse = my_mse(ys_valid_std, _my_y_valid_pred)\n",
    "print(f\"Your MSE should be roughly 6.8 and it is {_my_mse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0505c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check whether your model does not overfit by comparing the training and validation MSEs; they should have similar values for a model that does not overfit. Here you just have to run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbe2e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your training MSE is 5.856867595310951. Does your model overfit?\n"
     ]
    }
   ],
   "source": [
    "_my_y_train_pred = xs_train_polynomial @ _my_weights\n",
    "_my_train_mse = my_mse(ys_train_std, _my_y_train_pred)\n",
    "print(f\"Your training MSE is {_my_train_mse}. Does your model overfit?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
